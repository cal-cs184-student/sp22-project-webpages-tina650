<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2022</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Tina Li & Daniel Won, CS184-aax & CS184-ack </h2>
<h3 align="middle"><a href="https://cal-cs184-student.github.io/sp22-project-webpages-tina650/proj1/index.html">https://cal-cs184-student.github.io/sp22-project-webpages-tina650/proj1/index.html</a></h3>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p> In this project we rasterized various svg images by individually rendering the triangles that make up the svg files. 
  We implemented multiple methods of antialiasing with varying degrees of performance and quality. These include supersampling that takes multiple samples 
  within a pixel to produce accurate colors, as well as pixel and level sampling methods that apply textures to fit within an object of a lower-resolution 
  in the screen space. One interesting thing we learned from this project were the inner workings and mathematics behind how images are rendered and manipulated 
  in visual softwares like Adobe Photoshop. 
</p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>

  <p>
  In order to rasterize a triangle we use the simple approach of 2D Sampling, which means we sample the pixel center if it is inside the triangle. In order to do that we have 2 for loops. 
    This first one loops through the width and the second through the height of the triangle to get every pixel. Then we used the three line test to see if the center of the pixel is 
    inside the triangle. In order to do so we made sure to add (0.5, 0.5) to our coordinates of each pixel to check if the center of the pixel was inside. If the pixel was inside the triangle, 
    then we check the bounds. If 0 > floor(x), floor(x) >= width, 0 > floor(y), or floor(x) >= height then we end the function. If not then we fill the pixel. 
  </p>
  
  <p>
    This algorithm is no worse than the one that checks each sample within the bounding box of the triangle because my algorithm does exactly that. Therefore, it is no worse. 
  </p>

  <div style="display:flex;flex-direction:column;align-items:center;">
  <img src="images/basic_test6.PNG" style="width:375px; height:500px;align:middle;"/>
    <figcaption align="middle">Test 4</figcaption>
  
  <p>
    This screenshot is interesting because it shows how even though the triangle in the larger (zoomed out) picture looks like it is completely filled in, it is actually not. 
    As you can see there are pixels at the tip of this triangle drawing that don’t have their centers inside the triangle according to our 3 line tests. So they are not filled 
    in with color.
  </p>
  

<h3 align="middle">Part 2: Antialiasing triangles</h3>
  
  <p>
                  Our supersampling algorithm is based on our regular rasterization algorithm from Task 1. We have the same 2 for loops through the width and height 
                  of the picture and the three line tests. Some modifications we made to the resterization pipelines are that we have 2 more for loops right after our 
                  initial for loops and 3 line tests. These 2 new for loop loops through all the subpixels of each pixel to check if their center points are inside the 
                  triangle edges, and if they are they set the index of the subpixel in the sample buffer to the color.  Then, In resolve_to_framebuffer we added an if 
                  statement for if the sample_rate was greater than 1. Where we run 2 for loops to get all the subpixels’ color from the sample buffer and average it out
                  to find the average color which we then use that average color to fill that pixel. We then take that average color and fill the target frame buffer with 
                  this color. 

  </p>
                  
  <p> 
                  Supersampling is useful because it blurs the edges of the shapes, which in part make the image smoother. 
  </p>
          
  
  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/basic_test6.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Sample rate = 1</figcaption>
      </td>
      <td>
        <img src="images/test4_4.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Sample rate = 4</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/test4_9.png" align="middle" width="400px"/>
        <figcaption align="middle">Sample rate = 9</figcaption>
      </td>
      <td>
        <img src="images/test4_16.png" align="middle" width="400px"/>
        <figcaption align="middle">Sample rate = 16</figcaption>
      </td>
    </tr>
  </table>
</div>

  <p>
                  As you can see the supersample one has blurrier edges. The reason for this is because in supersampling we get the average color of all the subpixels of 
                  each pixel. So if it’s an edge pixel the color will not be just fully red or white, but how many subpixels’ centers are within the triangle determines 
                  the intensity of the red in the pixel. So as you can see when we increase the sample rate we are increasing the number of subpixels and getting blurrier 
                  edges which makes for smoother images. 
  </p>


<h3 align="middle">Part 3: Transforms</h3>
<p>
    For this part, we used the mathematical formula brought up during lecture.
    Translate and scale was simple to implement. 
  For rotate, it was a bit confusing as plugging in just the degree argument into sinusoidal functions in the given rotational matrix formula produced a 
  head graphic rotated slightly off from the source svg image. After consulting Piazza and investigating what units the sinusoidal functions used, 
  we figured out that we need to first convert the degree argument into radians. To do so, we multiplied deg by PI / 180, and then we inputted this 
  radian measurement into the matrix.
</p>
    
    <div style="display:flex;flex-direction:column;align-items:center;">
    <img src="images/robot.png" style="width:500px; height:375px;align:middle;"/>
    <figcaption align="middle">En Garde Robot</figcaption>
    
    <p>
      For this updated version of the cubeman, we decided to put him in a “fencing” position (originally meant to be a Spider-Man swinging towards a camera but 
      felt that this imagery was not as clear from the output image). To create this posture, we had to apply both rotations and translations to his right arm and 
      both legs to keep the illusion of connected joints.
    </p>


<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>
      
  <div style="display:flex;flex-direction:column;align-items:center;">
  <img src="images/tri.png" style="width:375px; height:500px;align:middle;"/>
    <figcaption align="middle">Test 4</figcaption>
    
    <p>
      Barycentric coordinates is a way to find a position, color, or other graphic elements within a triangle relative to the vertices of the triangle. 
      Depending on where a pixel is relative to each vertex and the value of a given graphic element at each vertex, the value of the graphic element we 
      are investigating will correspond to the proportional distances to each vertex, which creates a nearly smooth gradient of values. For example, the 
      above triangle shows this as each point lines up in a smooth transition between red, blue, and green, where each point’s color is a calculated value 
      based on its proportional distance from the red, green, and blue points.
    </p>
      
<div style="display:flex;flex-direction:column;align-items:center;">
    <img src="images/cir.png" style="width:500px; height:375px;align:middle;"/>
    <figcaption align="middle">Color Wheel Output</figcaption>
    
</div>


<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>
<p>
  Pixel sampling allows us to get a more accurate color relative to the image or texture we are trying to render for a given pixel rather than simply just grabbing 
  the color of whichever pixel we are currently calculating for. If we were to not do pixel sampling and do the naive way of simply picking out colors from the 
  corresponding pixel, we risk the image quality to look very jagged. To implement pixel sampling relative to texture mapping, we calculate Barycentric coordinates 
  for a given (x,y) pixel relative to the given screen space triangle coordinates and texture space triangle coordinates, and passing these (u,v) coordinates into a 
  SampleParams struct that is passed as an argument to the given texture’s sample method that retrieves a color using the appropriate sampling method.
</p>
    
<p>
  Nearest pixel sampling relies on the idea that the color of a given pixel will take the color of the closest pixel to its (u,v) Barycentric coordinates in the texture space. 
  Bilinear pixel sampling, on the other hand, looks at the colors of the surrounding set of 4 pixels and uses the pixel’s position relative to these 4 pixels via linear 
  interpolation to calculate the color from the proportional distances from these pixels.
</p>
    
    
      <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/near1.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Sampling: 1 Sample per Pixel</figcaption>
      </td>
      <td>
        <img src="images/near16.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Sampling: 16 Samples per Pixel</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/bi1.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear Sampling: 1 Sample per Pixel</figcaption>
      </td>
      <td>
        <img src="images/bilinear_16_pixel.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear Sampling: 16 Sample per Pixel</figcaption>
      </td>
    </tr>
  </table>
</div>


<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>
    
    <p>
      Level sampling is when the texture is too big for a given screen or object so we need to shrink and downsample the higher texture resolution to accurately 
      fit into the lower resolution. To implement this as seen in the specs, we first approximated the du/dx, dv/dx, du/dy, and dv/dy by translating (x+1, y) and (x, y+1) 
      into (u,v) barycentric coordinates and scaling it by the texture’s width and height. Using these differential vectors, we calculated level L = log_2(D) where D is 
      calculated via the formula brought up in class (or the max of sqrt(du/dx ^2 + dv/dx ^2) and sqrt(du/dy^2 + dv/dy^2) ). Based on the linear sampling method chosen, 
      we appropriately adjusted the level according to each one’s functionality.
    </p>
    
    <p>
      Based on the performance statistics given on Xcode:
<ul><li>Nearest at 1 sample per pixel: 73% CPU usage, 64.1 MB used, which was typically faster than bilinear sampling with a lower quality antialiasing</li>
<li>Bilinear at 1 sample per pixel: 85% CPU usage, 68.1 MB: relatively used more (but not extremely more) memory for a higher quality antialiasing</li>
<li>Bilinear at 16 samples per pixel: 99% CPU usage, 398 MB, which was significantly more memory than the original 1 sample per pixel</li>
  <li> Nearest pixel sampling, nearest level sampling, at 1 sample per pixel, approximately 5.8-6 ms: 77% CPU usage, 67.9 MB memory used, which is a tiny bit above nearest pixel sampling at level zero at a higher quality antialiasing but not as much consumption as bilinear pixel sampling at level zero
 </li>
  <li> Bilinear pixel sampling, nearest level sampling, at 1 sample per pixel, approximately 5.5 ms: 84% CPU usage, 67.8 MB memory used, which is almost the same as bilinear pixel sampling at level zero
 </li>
  <li> Nearest pixel sampling, bilinear level sampling, at 1 sample per pixel, approximately 5 - 5.5 ms: 82% CPU usage, 68.1 MB memory used, this has a similar quality to that of nearest pixel sampling at bilinear level sampling with very slight improvement in antialiasing in certain areas, and in terms of memory consumption, it performs nearly the same as well.
 </li>
  <li> Trilinear, at 1 sample per pixel: 84% CPU usage, 68.1 MB memory used, approximately 4.8 - 5 ms, out of all the sampling method pairing at 1 sample per pixel, this yielded the blurriest and most powerful antialiasing, without the memory usage changing much. There is a fairly significant jump between nearest pixel sampling with bilinear level sampling and trilinear sampling in terms of antialiasing power.
 </li>
    </ul>
    </p>
      
      <p>
        Looking at these statistics, there are a few things we can observe about the tradeoffs among the three methods. 
      </p>
      
      <p>
        Supersampling makes the antialiasing significantly better, blurring the edges and creating fewer jaggies due to it taking samples from a higher resolution of the original image. However, there is a huge tradeoff in performance as the speed becomes significantly slower and the memory usage gets significantly higher.

      </p>
      
      <p>
        Changing the pixel sampling method from nearest to bilinear pixel sampling can upgrade the antialiasing for jagged edges a bit. One tradeoff is that the amount of memory used can be a bit more as it usually went from around 70% to 80% CPU usage at level zero/nearest level sampling and from 82% to 84% CPU usage at bilinear level sampling. However, when it becomes trilinear sampling by pairing the method with nearest and bilinear level sampling, the tradeoff can be that it becomes a bit too blurred.

      </p>
      
      <p>
        Level sampling also has some antialiasing power although it is definitely not as strong as the differences in the other two methods. From the images we observed, there did not seem to be a huge difference between nearest level and bilinear level sampling. Memory usage and speed did not seem to change that much, but based on tiny differences, it did seem to be faster most likely due to it dealing with a lower resolution of an image and therefore less pixels.

      </p>
      
      <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/n_zero.png" align="middle" width="400px"/>
        <figcaption align="middle">NEAREST_ZERO</figcaption>
      </td>
      <td>
        <img src="images/n_n.png" align="middle" width="400px"/>
        <figcaption align="middle">NEAREST_NEAREST</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/n_bi.png" align="middle" width="400px"/>
        <figcaption align="middle">NEAREST_BILINEAR</figcaption>
      </td>
      <td>
        <img src="images/bi_n.png" align="middle" width="400px"/>
        <figcaption align="middle">BILINEAR_NEAREST</figcaption>
      </td>
    </tr>
  </table>
</div>      
    



<h2 align="middle">Section III: Art Competition</h2>
<p>If you are not participating in the optional art competition, don't worry about this section!</p>

<h3 align="middle">Part 7: Draw something interesting!</h3>

</body>
</html>
